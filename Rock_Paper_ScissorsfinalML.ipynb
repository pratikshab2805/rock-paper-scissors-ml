{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYLU9TOUWRUXew2tp62Ntu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikshab2805/rock-paper-scissors-ml/blob/main/Rock_Paper_ScissorsfinalML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q6IhuTPsasF",
        "outputId": "9c0cfcc4-bd29-400d-b33b-5b995b2f8d12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Check if model was saved\n",
        "model_path = '/content/drive/MyDrive/rps_model.h5'\n",
        "if os.path.exists(model_path):\n",
        "    print(\"âœ… Model was saved! Training completed before disconnect.\")\n",
        "else:\n",
        "    print(\"âŒ Model not found. Training might have stopped.\")\n",
        "\n",
        "# List what's in your folder\n",
        "drive_contents = os.listdir('/content/drive/MyDrive')\n",
        "print(\"\\nDrive contents:\", drive_contents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gaUgPc6RRFx",
        "outputId": "e316c63a-c246-4160-a8e0-ce00a5d213f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Model was saved! Training completed before disconnect.\n",
            "\n",
           
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "yWm2aC1hsefl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = DATASET_PATH = '/content/drive/MyDrive/rps-datset--'\n",
        "print(\"Dataset contents:\")\n",
        "print(os.listdir(DATASET_PATH))\n"
      ],
      "metadata": {
        "id": "uk8BW9LAsi1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "BATCH_SIZE = 16\n"
      ],
      "metadata": {
        "id": "Uz1nsXn_ssVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "id": "xqB2A7oms2ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define paths\n",
        "zip_path = '/content/drive/MyDrive/rps-datset--/RockPaperScissors.zip'\n",
        "extract_path = '/content/drive/MyDrive/rps-datset--'\n",
        "\n",
        "# Check if Drive is still connected\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    print(\"âŒ Error: Google Drive is disconnected. Please re-run the drive mount cell (the first cell in the notebook).\")\n",
        "else:\n",
        "    print(\"Extracting ZIP file...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(\"âœ… Extraction complete!\")\n",
        "\n",
        "        # Check what was extracted\n",
        "        print(\"\\nFolder contents after extraction:\")\n",
        "        contents = os.listdir(extract_path)\n",
        "        print(contents)\n",
        "\n",
        "        # Check subfolders\n",
        "        for item in contents:\n",
        "            full_path = os.path.join(extract_path, item)\n",
        "            if os.path.isdir(full_path):\n",
        "                num_images = len(os.listdir(full_path))\n",
        "                print(f\"  {item}/: {num_images} images\")\n",
        "\n",
        "    except OSError as e:\n",
        "        if \"Transport endpoint is not connected\" in str(e):\n",
        "            print(\"\\nâŒ Error: The connection to Google Drive was lost during extraction.\")\n",
        "            print(\"á€á€  FIX: Go to the top of the notebook, re-run 'drive.mount', then run this cell again.\")\n",
        "        else:\n",
        "            print(f\"âŒ An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "UbrCCfT4vN-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")"
      ],
      "metadata": {
        "id": "qaAG73xts8BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_gen = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "print(f\"\\nClass labels: {train_gen.class_indices}\")\n",
        "print(f\"Training samples: {train_gen.samples}\")\n",
        "print(f\"Validation samples: {val_gen.samples}\")\n"
      ],
      "metadata": {
        "id": "g92o9niTtARm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    # First Convolutional Block\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # 3 classes\n",
        "])"
      ],
      "metadata": {
        "id": "ACs9qGjktEC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"\\nModel Summary:\")\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "oJES2LEOtLLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/rps-datset--'\n",
        "\n",
        "# Classes to check\n",
        "classes = ['paper', 'rock', 'scissors']\n",
        "\n",
        "for class_name in classes:\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "\n",
        "    if os.path.exists(class_path):\n",
        "        files = os.listdir(class_path)\n",
        "        corrupted_files = []\n",
        "\n",
        "        for file in files:\n",
        "            file_path = os.path.join(class_path, file)\n",
        "\n",
        "            try:\n",
        "                # Try to open the image\n",
        "                img = Image.open(file_path)\n",
        "                img.verify()  # Verify it's a valid image\n",
        "            except Exception as e:\n",
        "                # If it fails, mark as corrupted\n",
        "                corrupted_files.append(file)\n",
        "                print(f\"âŒ Corrupted: {class_name}/{file}\")\n",
        "\n",
        "        # Delete corrupted files\n",
        "        for file in corrupted_files:\n",
        "            os.remove(os.path.join(class_path, file))\n",
        "            print(f\"   Deleted: {file}\")\n",
        "\n",
        "        print(f\"âœ… {class_name}/: {len(files) - len(corrupted_files)} valid images remaining\\n\")"
      ],
      "metadata": {
        "id": "YUsofPZ3skul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# --- Configurations ---\n",
        "DATASET_PATH = '/content/drive/MyDrive/rps-datset--'\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# 1. Clear session to avoid internal graph errors\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# 2. Define classes\n",
        "classes = ['rock', 'paper', 'scissors']\n",
        "\n",
        "# 3. Initialize Data Generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=classes,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    classes=classes,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# 4. Check if images were actually loaded\n",
        "if train_gen.samples == 0:\n",
        "    print(\"\\nâŒ ERROR: No images found in the dataset folder!\")\n",
        "    print(\"This is likely because the extraction in cell UbrCCfT4vN-y was interrupted.\")\n",
        "    print(\"FIX: Re-run cell UbrCCfT4vN-y and wait for it to finish, then run this cell again.\")\n",
        "else:\n",
        "    # 5. Define Model Architecture\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # 6. Compile and Train\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(f'\\nClass labels: {train_gen.class_indices}')\n",
        "    print('\\nðŸš€ Starting clean training...\\n')\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=5,\n",
        "        validation_data=val_gen,\n",
        "        verbose=1\n",
        "    )"
      ],
      "metadata": {
        "id": "2AsbGVuWtOlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if 'history' in globals():\n",
        "    print(\"\\nâœ… Training Complete!\")\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"âŒ Error: 'history' not found. Please run the training cell (2AsbGVuWtOlt) first and wait for it to finish.\")"
      ],
      "metadata": {
        "id": "GG-p_iT8tTSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'model' in globals():\n",
        "    MODEL_SAVE_PATH = '/content/drive/MyDrive/rps_model.h5'\n",
        "    model.save(MODEL_SAVE_PATH)\n",
        "    print(f\"\\nâœ… Model saved to: {MODEL_SAVE_PATH}\")\n",
        "else:\n",
        "    print(\"âŒ Error: The 'model' variable is not defined.\")\n",
        "    print(\"Please ensure that you have successfully run the training cell (cell 2AsbGVuWtOlt) before attempting to save.\")"
      ],
      "metadata": {
        "id": "iAVE_2PztgL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/rps_model.h5')\n",
        "\n",
        "# ============================================\n",
        "# STEP 1: Create Test Data Generator\n",
        "# ============================================\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "BATCH_SIZE = 16\n",
        "DATASET_PATH = '/content/drive/MyDrive/rps-datset--'\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ============================================\n",
        "# STEP 2: Get Predictions\n",
        "# ============================================\n",
        "print(\"ðŸ” Evaluating model on test data...\\n\")\n",
        "\n",
        "predictions = model.predict(test_gen)\n",
        "true_labels = test_gen.classes\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "class_names = list(test_gen.class_indices.keys())\n",
        "print(f\"Classes: {class_names}\\n\")\n",
        "\n",
        "# ============================================\n",
        "# STEP 3: Calculate Accuracy\n",
        "# ============================================\n",
        "accuracy = np.mean(predicted_labels == true_labels)\n",
        "print(f\"âœ… Overall Accuracy: {accuracy*100:.2f}%\\n\")\n",
        "\n",
        "# ============================================\n",
        "# STEP 4: Classification Report\n",
        "# ============================================\n",
        "print(\"ðŸ“Š Classification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
        "\n",
        "# ============================================\n",
        "# STEP 5: Confusion Matrix\n",
        "# ============================================\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… Evaluation Complete!\")"
      ],
      "metadata": {
        "id": "Dt6oWWKLP_UQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/rps_model.h5')\n",
        "\n",
        "IMG_HEIGHT = 128  # Match your training size\n",
        "IMG_WIDTH = 128\n",
        "\n",
        "class_names = ['paper', 'rock', 'scissors']\n",
        "\n",
        "# Game logic\n",
        "def get_computer_choice():\n",
        "    return np.random.choice(class_names)\n",
        "\n",
        "def determine_winner(user_choice, computer_choice):\n",
        "    if user_choice == computer_choice:\n",
        "        return \"Draw! ðŸ¤\"\n",
        "\n",
        "    if user_choice == 'rock':\n",
        "        return \"You Win! ðŸŽ‰\" if computer_choice == 'scissors' else \"Computer Wins! ðŸ¤–\"\n",
        "    elif user_choice == 'paper':\n",
        "        return \"You Win! ðŸŽ‰\" if computer_choice == 'rock' else \"Computer Wins! ðŸ¤–\"\n",
        "    elif user_choice == 'scissors':\n",
        "        return \"You Win! ðŸŽ‰\" if computer_choice == 'paper' else \"Computer Wins! ðŸ¤–\"\n",
        "\n",
        "print(\"ðŸŽ® Rock Paper Scissors Game Started!\")\n",
        "print(\"ðŸ“· Capturing image from webcam...\\n\")\n",
        "\n",
        "# Capture image from webcam\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "js_code = \"\"\"\n",
        "async function takePhoto(quality) {\n",
        "  const div = document.createElement('div');\n",
        "  const capture = document.createElement('canvas');\n",
        "  const video = document.createElement('video');\n",
        "  video.setAttribute('autoplay', '');\n",
        "  video.setAttribute('playsinline', '');\n",
        "\n",
        "  const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "  video.srcObject = stream;\n",
        "\n",
        "  await new Promise(r => video.onloadedmetadata = r);\n",
        "  const [w,h] = [video.videoWidth, video.videoHeight];\n",
        "  capture.getContext('2d').drawImage(video, 0, 0, w, h);\n",
        "  stream.getTracks().forEach(track => track.stop());\n",
        "\n",
        "  return capture.toDataURL('image/jpeg', quality);\n",
        "}\n",
        "takePhoto(0.8);\n",
        "\"\"\"\n",
        "\n",
        "image_data = eval_js(js_code)\n",
        "image_data = image_data.split(',')[1]\n",
        "image_bytes = base64.b64decode(image_data)\n",
        "image = Image.open(io.BytesIO(image_bytes))\n",
        "\n",
        "# Resize image\n",
        "image_resized = image.resize((IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "# Display captured image\n",
        "cv2_imshow(np.array(image_resized))\n",
        "\n",
        "# Predict\n",
        "image_array = np.array(image_resized) / 255.0\n",
        "image_array = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "prediction = model.predict(image_array)\n",
        "user_choice_idx = np.argmax(prediction)\n",
        "user_choice = class_names[user_choice_idx]\n",
        "confidence = prediction[0][user_choice_idx]\n",
        "\n",
        "print(f\"\\nðŸ¤š Your Choice: {user_choice.upper()}\")\n",
        "print(f\"ðŸ“Š Confidence: {confidence*100:.2f}%\\n\")\n",
        "\n",
        "# Game result\n",
        "computer_choice = get_computer_choice()\n",
        "print(f\"ðŸ¤– Computer Choice: {computer_choice.upper()}\\n\")\n",
        "\n",
        "result = determine_winner(user_choice, computer_choice)\n",
        "print(f\"ðŸŽ¯ Result: {result}\\n\")\n",
        "\n",
        "print(\"ðŸ“ˆ Model Predictions:\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"  {class_name.capitalize()}: {prediction[0][i]*100:.2f}%\")"
      ],
      "metadata": {
        "id": "p5H8G3MtTfok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
